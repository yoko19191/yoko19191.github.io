<!DOCTYPE html> <html><head>
		<title>这就是ChatGPT</title>
		<base href="../../">
		<meta id="root-path" root-path="../../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="🌱 Digital-Garden - 这就是ChatGPT">
		<meta property="og:title" content="这就是ChatGPT">
		<meta property="og:description" content="🌱 Digital-Garden - 这就是ChatGPT">
		<meta property="og:type" content="website">
		<meta property="og:url" content="💾-科技工程/aigc/这就是chatgpt.html">
		<meta property="og:image" content="https://vip2.loli.io/2023/11/30/ZexiySjzdE48t79.png">
		<meta property="og:site_name" content="🌱 Digital-Garden">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="preload" href="lib/styles/other-plugins.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/other-plugins.css"></noscript><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager native-scrollbars theme-light show-inline-title show-ribbon"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles"></style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="这就是ChatGPT"><p dir="auto">这就是ChatGPT</p></h1><div><p dir="auto"><a href="?query=tag:%E5%B0%8F%E8%AE%B0" class="tag" target="_blank" rel="noopener">#小记</a> <a href="?query=tag:%E6%8A%84%E5%BD%95" class="tag" target="_blank" rel="noopener">#抄录</a> <a href="?query=tag:%E8%AE%A1%E7%AE%97%E6%9C%BA" class="tag" target="_blank" rel="noopener">#计算机</a> <a href="?query=tag:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" class="tag" target="_blank" rel="noopener">#人工智能</a></p></div><div><p dir="auto"><strong>Stephen Wolfram</strong> 著<br>
人民邮电出版社</p></div><div><p dir="auto"><a data-tooltip-position="top" aria-label="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/" rel="noopener" class="external-link" href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/" target="_blank">在线版-What Is ChatGPT Doing … and Why Does It Work?—Stephen Wolfram Writings</a></p></div><div class="admonition-parent admonition-hint-parent"><div class="callout admonition admonition-hint admonition-plugin " style="--callout-color: 0, 191, 165;" data-callout="hint" data-callout-fold="" data-callout-metadata=""><div class="callout-title admonition-title "><div class="callout-icon admonition-title-icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="fire" class="svg-inline--fa fa-fire fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M216 23.86c0-23.8-30.65-32.77-44.15-13.04C48 191.85 224 200 224 288c0 35.63-29.11 64.46-64.85 63.99-35.17-.45-63.15-29.77-63.15-64.94v-85.51c0-21.7-26.47-32.23-41.43-16.5C27.8 213.16 0 261.33 0 320c0 105.87 86.13 192 192 192s192-86.13 192-192c0-170.29-168-193-168-296.14z"></path></svg></div><div class="callout-title-inner admonition-title-content">Hint</div></div><div class="callout-content admonition-content"><p dir="auto">这本书提纲挈领, 高屋建瓴. 简洁明了解释了GPT的基本工作原理, 涵盖需要理解需要的机器学习、自然语言处理、神经网络的前置知识.</p>
<p dir="auto">但是这本书中最有价值, 我认为是"GPT的内部原理"和对语义空间的理解. </p>
<p dir="auto">以下是我的一些收获:</p>
<ol>
<li dir="auto">即使基础规则简单, 计算过程本身也可以极大的放大表面的系统复杂性. 我们再一次见证了AlexNet的时刻. 大力出奇迹</li>
<li dir="auto">人脑的神经元之间可以互相开火, GPT的神经元是只是单单forward传播. GPT用1750亿(GPT-3)的参数, 可以很大程度上捕捉又人脑1000亿神经元的100万亿个连接所拥有的语言及其背后思维的能力. 积极的看, 人脑有希望被计算暴力模拟出来. 悲观的看, 人类的语言远比我们之前想象的简单. </li>
<li dir="auto">计算不可约性, 保证了即使是AGI, 也永远不会像上帝一样全知全能.</li>
<li dir="auto">神经网络拟合复杂问题的难度可能比简单问题更加简单. 这是因为复杂问题在特征空间上有更多的方向更加容易收敛. 而简单问题则容易陷入到局部最优.</li>
<li dir="auto">LLM在未来很长时间都只是一个概率模型. 这导致了诸如幻觉之类的问题, 从根本上无法解决. </li>
<li dir="auto">作者在85页用一个括号平衡预测的例子展示想要获得文本中即使看似简单的规则, 也并非易事.</li>
<li dir="auto">人类一直尝试用语言描述我们观察到的世界. 在20世纪是数学语言. 在21世纪可能是计算语言. ChatGPT最终可以在不考虑修辞的情况下, 捕捉语义空间背后的世界规则. 非欧几何</li>
<li dir="auto">作者比较了ChatGPT(概率模型)和Wolframe Alpha(符号推理)在结构化问题中对比. 展示了两个技术之间的互补. 为未来更精准的语言模型提供了方向.</li>
</ol></div></div></div><div class="admonition-parent admonition-note-parent"><div class="callout admonition admonition-note admonition-plugin " style="--callout-color: 68, 138, 255;" data-callout="note" data-callout-fold="" data-callout-metadata=""><div class="callout-title admonition-title "><div class="callout-icon admonition-title-icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="pencil-alt" class="svg-inline--fa fa-pencil-alt fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"></path></svg></div><div class="callout-title-inner admonition-title-content">Note</div></div><div class="callout-content admonition-content"><p dir="auto">这是书中一些重要的概念:</p>
<p dir="auto">不同的权重的网络可能会在相同样本的训练后获得相同的损失函数. 即在样本上是不同但等效的. 但这并不难表示他们在样本之外的行为也是相同的, 这就是<strong>外插(extraapolation)</strong></p>
<p dir="auto"><strong>计算等价原理(Principle of Computational Equivalence, PCE)</strong>: 即使是最简单的规则系统，也可能展现出与最复杂系统相同级别的计算能力。例如，沃尔夫勒姆认为，元胞自动机（一种简单的计算模型, Turing complete）在某些情况下可以表现出与图灵机（一种理论上的通用计算模型）相同的计算复杂性。人类(社会,心智)的建构和自然界中复杂系统的建构没有两样. </p>
<p dir="auto"><strong>计算不可约性原理</strong>(Principle of Computational Irreducibility): 某些问题或系统是“不可约”的，即不存在捷径或简化方法来预测它们的结果。例如，某些复杂的气象系统的未来状态可能只能通过实际模拟整个系统的演进来确定，而不能通过更简单的公式或预测方法来实现。这就意味着即使是最强的AI也有还没有计算到事物.</p>
<p dir="auto"><strong>第一性原理（First Principles）</strong>是一种深入分析和解决问题的方法。它涉及将复杂问题分解为最基本的、不可再分的真理或假设，然后从这些基础出发构建解决方案。</p>
<p dir="auto"><strong>图灵完备（Turing completeness</strong>）是如果一个系统可以通过算法或计算过程解决的问题，那么它就是图灵完备的.</p>
<p dir="auto"><strong>Ruliad</strong> 由Stephen Wolfram提出, 被定义为一切计算上可能的事物的纠缠极限. 即所有可能的计算规则以及这些规则所有可能的应用方式得到的结果. 他认为我们作为观察者的经验实际上是基于我们对Ruliad的采样。由于我们的知觉和认知能力有限，我们只能感知Ruliad的某些方面。这种有限的采样导致我们观察到的宇宙遵循特定的物理定律，如广义相对论和量子力学。<a data-tooltip-position="top" aria-label="https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/" rel="noopener" class="external-link" href="https://writings.stephenwolfram.com/2021/11/the-concept-of-the-ruliad/" target="_blank">The Concept of the Ruliad—Stephen Wolfram Writings</a><br>
<a data-tooltip-position="top" aria-label="https://mathworld.wolfram.com/Ruliad.html" rel="noopener" class="external-link" href="https://mathworld.wolfram.com/Ruliad.html" target="_blank">Ruliad -- from Wolfram MathWorld</a></p></div></div></div><div class="admonition-parent admonition-check-parent"><div class="callout admonition admonition-check admonition-plugin " style="--callout-color: 0, 200, 83;" data-callout="check" data-callout-fold="" data-callout-metadata=""><div class="callout-title admonition-title "><div class="callout-icon admonition-title-icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="check-circle" class="svg-inline--fa fa-check-circle fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"></path></svg></div><div class="callout-title-inner admonition-title-content">Check</div></div><div class="callout-content admonition-content"><p dir="auto">大型语言模型（LLM）基于统计学习的原理，通过分析和学习海量文本数据，捕捉语言规律和模式，以生成连贯和相关的文本输出。</p></div></div></div><div class="admonition-parent admonition-hint-parent"><div class="callout admonition admonition-hint admonition-plugin " style="--callout-color: 0, 191, 165;" data-callout="hint" data-callout-fold="" data-callout-metadata=""><div class="callout-title admonition-title "><div class="callout-icon admonition-title-icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="fire" class="svg-inline--fa fa-fire fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M216 23.86c0-23.8-30.65-32.77-44.15-13.04C48 191.85 224 200 224 288c0 35.63-29.11 64.46-64.85 63.99-35.17-.45-63.15-29.77-63.15-64.94v-85.51c0-21.7-26.47-32.23-41.43-16.5C27.8 213.16 0 261.33 0 320c0 105.87 86.13 192 192 192s192-86.13 192-192c0-170.29-168-193-168-296.14z"></path></svg></div><div class="callout-title-inner admonition-title-content">Hint</div></div><div class="callout-content admonition-content"><p dir="auto">有效加速主义(Effective Accelerationism, e/Acc)是最近在科技区, 特别是硅谷技术人员兴起的一种自然科学信仰.  他们基于热力学第二定律(热量不能自发地从低温体流向高温体，除非有外部工作介入), 有机生命持续的追求自身的熵减, 却同时加速了宇宙的熵增, 由此认为由技术资本驱动的科技革命和生产力发展是必然发生的, 人们不应该拒绝这种必然发生的变化, 而是积极推动它, 不顾一切的发展科技. 主动适应变化就是人类的义务，人的利益或者其他的任何理由都不应该成为阻碍技术发展的理由。</p>
<p dir="auto">PS:属于极端工业党了hehe, 而且科学不承认真理, 是对观察的总结和推理</p>
<p dir="auto"><a data-tooltip-position="top" aria-label="https://effectiveacceleration.tech" rel="noopener" class="external-link" href="https://effectiveacceleration.tech" target="_blank">Effective Accelerationism</a><br>
<a data-tooltip-position="top" aria-label="https://a16z.com/the-techno-optimist-manifesto/" rel="noopener" class="external-link" href="https://a16z.com/the-techno-optimist-manifesto/" target="_blank">The Techno-Optimist Manifesto | Andreessen Horowitz</a><br>
<a data-tooltip-position="top" aria-label="https://beff.substack.com/p/notes-on-eacc-principles-and-tenets" rel="noopener" class="external-link" href="https://beff.substack.com/p/notes-on-eacc-principles-and-tenets" target="_blank">Notes on e/acc principles and tenets</a></p></div></div></div><div><ul>
<li data-line="0" dir="auto" class="lc-list-callout" data-callout="?" style="--lc-callout-color: 255, 145, 0;"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="lc-li-wrapper">
<p><span class="lc-list-marker">?</span> ChatGPT 能做什么?</p>
</span><ul>
<li data-line="1" dir="auto">Companionship(教练, 外语老师...)</li>
<li data-line="2" dir="auto">Answer question(搜集整合资料)</li>
<li data-line="3" dir="auto">Utility(综合资料)</li>
<li data-line="4" dir="auto"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Creativity
<ul>
<li data-line="5" dir="auto">他认为创造遵循 overgenerate creativity, filtering out, output</li>
<li data-line="6" dir="auto">这种路径非常适合AI</li>
</ul>
</li>
<li data-line="7" dir="auto">Embedded into existing applications</li>
</ul>
</li>
<li data-line="8" dir="auto" class="lc-list-callout" data-callout="!" style="--lc-callout-color: 255, 23, 68;"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="lc-li-wrapper">
<p><span class="lc-list-marker">!</span> 使用Multi-step Planning(AutoGPT, Baby AGI)来形成工作流</p>
</span><ul>
<li data-line="9" dir="auto">可以使用Steamship来完成这样的工作</li>
<li data-line="10" dir="auto"><img alt="image.png" src="https://vip2.loli.io/2023/11/30/ZexiySjzdE48t79.png" referrerpolicy="no-referrer"></li>
</ul>
</li>
<li data-line="12" dir="auto">
<p>Stephen Wolfram,作者认为世间万物都可以用简单的规则计算和模拟, 这点和GPT通过简单的自回归的技术路线有相同之处.</p>
</li>
<li data-line="13" dir="auto" class="lc-list-callout" data-callout="!" style="--lc-callout-color: 255, 23, 68;"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="lc-li-wrapper">
<p><span class="lc-list-marker">!</span> 它认为在未来的AGI时代, 为人们提供了这样的建议</p>
</span><ul>
<li data-line="14" dir="auto"><strong>最高效的方式是发掘新的可能性，定义对自己有价值的东西</strong></li>
<li data-line="15" dir="auto"><strong>从现在的回答问题转向学会如何提出问题，以及如何确定哪些问题值得提出。也就是从知识执行转向知识战略。</strong></li>
<li data-line="16" dir="auto"><strong>知识广度和思维清晰度将很重要。</strong></li>
<li data-line="17" dir="auto"><strong>直接学习所有详细的知识已经变得不必要了：我们可以在更高的层次上学习和工作，抽象掉许多具体的细节。“整合”，而不是专业化。尽可能广泛、深入地思考，尽可能多地调用知识和范式。</strong></li>
<li data-line="18" dir="auto"><strong>学会使用工具来做事。过去我们更倚重逻辑和数学，以后要特别注意利用计算范式，并运用与计算直接相关的思维方式。</strong></li>
</ul>
</li>
<li data-line="19" dir="auto" class="lc-list-callout" data-callout="%" style="--lc-callout-color: 158, 158, 158;"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="lc-li-wrapper">
<p><span class="lc-list-marker">%</span> fun fact of GPT</p>
</span><ul>
<li data-line="20" dir="auto">2015年 OpenAI 成立</li>
<li data-line="21" dir="auto">2017.PPO; 2018.GPT-1; 2019,GPT-2; 2020, JukeBox; 2020, ImageGPT,GPT-3; 2021, CLIP; Whisper, 2022; 2023, GPT-4</li>
<li data-line="22" dir="auto" class="lc-list-callout" data-callout="!" style="--lc-callout-color: 255, 23, 68;"><span class="lc-li-wrapper"><span class="lc-list-marker">!</span> GPT是Decoder-only的路径, 即用当前Token来预测下一个Token(不是生成器而是解释器)</span></li>
</ul>
</li>
<li data-line="23" dir="auto" class="lc-list-callout" data-callout="!" style="--lc-callout-color: 255, 23, 68;"><div class="list-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div><span class="lc-li-wrapper">
<p><span class="lc-list-marker">!</span> 对于GPT业界大概有三种看法</p>
</span><ul>
<li data-line="24" dir="auto">Yann LeCun, 类似GPT的自回归模型有明确缺陷, 这条道路不能抵达通向 AGI 的世界模型</li>
<li data-line="25" dir="auto">Yoshua Bengio, 同样任务GPT的技术线路无法达到AGI, 但承认大模型的能力</li>
<li data-line="26" dir="auto">Geoffrey Hinton, 认为<strong>大模型可以学习到真实世界的压缩表示</strong>, 反向传播, 知错能改的能力会使得神经网络的能力跃升</li>
</ul>
</li>
<li data-line="27" dir="auto">
<p>GPT-3有1750亿个人参数</p>
</li>
<li data-line="28" dir="auto">
<p>生活中大多任务和人类的感知有关(human-like task), 并没有一个明确的数学解析式</p>
</li>
</ul></div><div><p dir="auto">作者然后用图片和例子详细介绍了样本, 样本空间, 特征空间, 权重, 神经网络, 卷积神经网络, 目标函数, 反向传播的概念</p></div><div><p dir="auto">NLP的工作原理</p></div><div><ul>
<li data-line="0" dir="auto">任务目标: 让当前文本获得合理的延续</li>
<li data-line="1" dir="auto">统计文本的字母频率, 选取最高的字母延续文本</li>
<li data-line="2" dir="auto">设置一个“temperature"用于表示随机选择概率最高字母的频率</li>
<li data-line="3" dir="auto">将单个字母扩展到n-gram, 即所谓Token, 会让延续文本变得越来越“真实”</li>
<li data-line="4" dir="auto">训练文本越大, 也会越“真实”, 这就是大模型</li>
</ul></div><div><p dir="auto">GPT</p></div><div class="admonition-parent admonition-check-parent"><div class="callout admonition admonition-check admonition-plugin " style="--callout-color: 0, 200, 83;" data-callout="check" data-callout-fold="" data-callout-metadata=""><div class="callout-title admonition-title "><div class="callout-icon admonition-title-icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="check-circle" class="svg-inline--fa fa-check-circle fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"></path></svg></div><div class="callout-title-inner admonition-title-content">Check</div></div><div class="callout-content admonition-content"><p dir="auto"><strong>数据增强</strong>是机器学习里一个非常重要的概念, 在NLP中数据增强大致有以下几类:</p>
<ul>
<li dir="auto"><strong>词汇替换（Lexical Substitution）</strong>：这种方法涉及到替换句子中的某些词语。例如，可以使用同义词替换原始句子中的词语，或者使用词嵌入（如Word2Vec或GloVe）找到与原始词语语义相近的词语进行替换。</li>
<li dir="auto"><strong>回译（Back Translation）</strong>：这种方法涉及将文本翻译成一种或多种不同的语言，然后再翻译回原始语言。这种方法可以产生与原始文本在意思上相近但在表达上略有差异的文本。</li>
<li dir="auto"><strong>句子重组（Sentence Shuffling）</strong>：对于某些任务，比如文本分类，可以通过改变句子的顺序来增加数据的多样性，前提是这种重组不会改变文本的总体意义。</li>
<li dir="auto"><strong>生成式方法（Generative Methods）</strong>：利用语言模型生成新的文本数据。例如，可以使用GPT-3或其他先进的生成式模型来创建新的句子或文本段落。</li>
<li dir="auto"><strong>数据扩充库（Data Augmentation Libraries）</strong>：例如，<code>nlpaug</code>、<code>TextAttack</code>等库提供了多种用于NLP数据增强的工具和方法。</li>
<li dir="auto"><strong>噪声注入（Noise Injection）</strong>：通过向文本中添加噪声（如打乱字母顺序、插入随机字符等）来创建新的样本。这种方法可以帮助模型学习更加鲁棒的特征。</li>
<li dir="auto"><strong>删除和插入（Deletion and Insertion）</strong>：从句子中随机删除某些词语或在句子中插入新的词语，这有助于模型学习从不完整的输入中提取信息。</li>
<li dir="auto"><strong>规则基础的方法（Rule-based Methods）</strong>：使用特定的语言规则来改写句子。例如，可以通过改变时态或语态来创建新的句子版本。</li>
</ul></div></div></div><div><p dir="auto">GPT在训练时, 把一段文字遮蔽. 没有遮蔽的文本作为训练输入, 未被遮蔽的完整文本作为正确值. 由此, GPT就可以从任意文本中进行学习. </p></div><div><ul>
<li data-line="0" dir="auto">神经网络的缩放量与数据量有近似幂律缩放的关系</li>
<li data-line="1" dir="auto">由于网络的训练是用微积分进行逐步改进(BP), 所以训练的精度不是重点(一般8bit就够了)</li>
<li data-line="2" dir="auto"></li>
</ul></div><div><p dir="auto">神经网络大小和能力的关系</p></div><div><ul>
<li data-line="0" dir="auto">强调人脑很难理解程式化的形式.(e.g.递归)</li>
<li data-line="1" dir="auto">计算不可约性更加为人脑理解非平凡问题制造了障碍</li>
</ul></div><div><p dir="auto">强调了Embedding. 即将文本映射到数字的技术.</p></div><div><ul>
<li data-line="0" dir="auto">Softmax作为输出层, 输出概率</li>
</ul></div><div class="heading-wrapper"><h2 data-heading="Up to date News" dir="auto" class="heading" id="Up_to_date_News"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>Up to date News</h2><div class="heading-children"><div><ul>
<li data-line="0" dir="auto">2023年6月，国务院办公厅发布《国务院2023年度立法工作计划》，《人工智能法》已列入立法计划 </li>
<li data-line="1" dir="auto">2023年7月，《生成式人工智能服务管理暂行办法》正式落地，并宣布自2023年8月15日起施行 </li>
<li data-line="2" dir="auto">2023年8月底，大模型牌照首批迅速上线 </li>
</ul></div><div class="mod-footer"></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="💾-科技工程/aigc/这就是chatgpt.html#这就是ChatGPT"><div class="tree-item-contents heading-link" heading-name="这就是ChatGPT"><span class="tree-item-title">这就是ChatGPT</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="💾-科技工程/aigc/这就是chatgpt.html#Up_to_date_News"><div class="tree-item-contents heading-link" heading-name="Up to date News"><span class="tree-item-title">Up to date News</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>